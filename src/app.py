import streamlit as st
import cv2
import numpy as np
import mediapipe as mp
from PIL import Image, UnidentifiedImageError
import copy
from streamlit_drawable_canvas import st_canvas
import json
import math
from typing import Dict, Tuple, Optional, List, Any
import hashlib

# Streamlit page config
st.set_page_config(
    page_title="é¡”ç”»åƒæ“ä½œãƒ—ãƒ­ã‚°ãƒ©ãƒ ",
    page_icon="ğŸ‘¤",
    layout="wide"
)

# --- MediaPipe Setup ---
mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

# --- Constants ---
CANVAS_WIDTH = 600  # ã‚­ãƒ£ãƒ³ãƒã‚¹ã®å›ºå®šå¹…
CANVAS_HEIGHT = 800  # ã‚­ãƒ£ãƒ³ãƒã‚¹ã®æœ€å¤§é«˜ã•

# --- Application Configuration ---
class AppConfig:
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã®é›†ç´„ã‚¯ãƒ©ã‚¹"""
    DEFAULT_MOVEMENT_THRESHOLD = 5.0  # æµ®å‹•å°æ•°ç‚¹ã§ã®é–¾å€¤
    MAX_HISTORY_SIZE = 20
    COORDINATE_PRECISION = 6  # åº§æ¨™è¨ˆç®—ã®å°æ•°ç‚¹ç²¾åº¦
    
    # ç‰¹å¾´ç‚¹ã‚°ãƒ«ãƒ¼ãƒ—å®šç¾©ï¼ˆè¤‡æ•°ç‚¹ã®å¹³å‡åŒ–ç”¨ï¼‰
    LANDMARK_GROUPS = {
        'left_eye_center': [159, 158, 157, 173],  # å·¦ç›®å‘¨è¾º4ç‚¹ã®å¹³å‡
        'right_eye_center': [386, 385, 384, 398],  # å³ç›®å‘¨è¾º4ç‚¹ã®å¹³å‡
        'nose_tip': [1, 2],  # é¼»å…ˆå‘¨è¾º2ç‚¹ã®å¹³å‡
        'nose_bridge': [6, 9],  # é¼»æ¢å‘¨è¾º2ç‚¹ã®å¹³å‡
        'left_nostril': [131, 134, 126],  # å·¦å°é¼»å‘¨è¾º3ç‚¹ã®å¹³å‡
        'right_nostril': [102, 49, 48]  # å³å°é¼»å‘¨è¾º3ç‚¹ã®å¹³å‡
    }

# --- Classes and Functions ---

class CoordinateConverter:
    """
    åº§æ¨™å¤‰æ›ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹
    
    æµ®å‹•å°æ•°ç‚¹è¨ˆç®—ã§ç²¾åº¦ã‚’ä¿æŒã—ã€é€†å¤‰æ›ã®æ•´åˆæ€§ã‚’ä¿è¨¼ã—ã¾ã™ã€‚
    """
    
    @staticmethod
    def scale_to_canvas(real_coords: Dict[str, float], 
                       real_size: Tuple[int, int], 
                       canvas_size: Tuple[int, int]) -> Dict[str, float]:
        """
        å®Ÿéš›ã®ç”»åƒåº§æ¨™ã‚’ã‚­ãƒ£ãƒ³ãƒã‚¹åº§æ¨™ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆé«˜ç²¾åº¦ç‰ˆï¼‰
        
        Args:
            real_coords: å®Ÿéš›ã®ç”»åƒåº§æ¨™ {'x': float, 'y': float}
            real_size: å®Ÿéš›ã®ç”»åƒã‚µã‚¤ã‚º (width, height)
            canvas_size: ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚º (width, height)
            
        Returns:
            ã‚­ãƒ£ãƒ³ãƒã‚¹åº§æ¨™ {'x': float, 'y': float}ï¼ˆæµ®å‹•å°æ•°ç‚¹ã§è¿”ã™ï¼‰
        """
        real_w, real_h = real_size
        canvas_w, canvas_h = canvas_size
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•°ã®è¨ˆç®—ã‚’æ”¹å–„ï¼ˆé«˜ç²¾åº¦ï¼‰
        scale_x = canvas_w / real_w
        scale_y = canvas_h / real_h
        
        # åº§æ¨™å¤‰æ›ã®ç²¾åº¦ã‚’å‘ä¸Š
        return {
            'x': round(real_coords['x'] * scale_x, AppConfig.COORDINATE_PRECISION),
            'y': round(real_coords['y'] * scale_y, AppConfig.COORDINATE_PRECISION)
        }
    
    @staticmethod
    def scale_to_real(canvas_coords: Dict[str, float], 
                     real_size: Tuple[int, int], 
                     canvas_size: Tuple[int, int]) -> Dict[str, float]:
        """
        ã‚­ãƒ£ãƒ³ãƒã‚¹åº§æ¨™ã‚’å®Ÿéš›ã®ç”»åƒåº§æ¨™ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆé«˜ç²¾åº¦ç‰ˆï¼‰
        
        Args:
            canvas_coords: ã‚­ãƒ£ãƒ³ãƒã‚¹åº§æ¨™ {'x': float, 'y': float}
            real_size: å®Ÿéš›ã®ç”»åƒã‚µã‚¤ã‚º (width, height)
            canvas_size: ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚º (width, height)
            
        Returns:
            å®Ÿéš›ã®ç”»åƒåº§æ¨™ {'x': float, 'y': float}ï¼ˆæµ®å‹•å°æ•°ç‚¹ã§è¿”ã™ï¼‰
        """
        real_w, real_h = real_size
        canvas_w, canvas_h = canvas_size
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•°ã®è¨ˆç®—ã‚’æ”¹å–„ï¼ˆé«˜ç²¾åº¦ï¼‰
        scale_x = real_w / canvas_w
        scale_y = real_h / canvas_h
        
        # åº§æ¨™å¤‰æ›ã®ç²¾åº¦ã‚’å‘ä¸Š
        return {
            'x': round(canvas_coords['x'] * scale_x, AppConfig.COORDINATE_PRECISION),
            'y': round(canvas_coords['y'] * scale_y, AppConfig.COORDINATE_PRECISION)
        }
    
    @staticmethod
    def verify_conversion_integrity(original_coords: Dict[str, float],
                                  real_size: Tuple[int, int],
                                  canvas_size: Tuple[int, int]) -> bool:
        """
        åº§æ¨™å¤‰æ›ã®å¾€å¾©æ•´åˆæ€§ã‚’æ¤œè¨¼ï¼ˆæ”¹å–„ç‰ˆï¼‰
        
        Args:
            original_coords: å…ƒã®åº§æ¨™
            real_size: å®Ÿéš›ã®ç”»åƒã‚µã‚¤ã‚º
            canvas_size: ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚º
            
        Returns:
            æ•´åˆæ€§ãŒä¿ãŸã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹
        """
        try:
            # å¾€å¾©å¤‰æ›ãƒ†ã‚¹ãƒˆ
            canvas_coords = CoordinateConverter.scale_to_canvas(original_coords, real_size, canvas_size)
            restored_coords = CoordinateConverter.scale_to_real(canvas_coords, real_size, canvas_size)
            
            # è¨±å®¹èª¤å·®å†…ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆ1ãƒ”ã‚¯ã‚»ãƒ«ä»¥å†…ï¼‰
            error_x = abs(original_coords['x'] - restored_coords['x'])
            error_y = abs(original_coords['y'] - restored_coords['y'])
            
            # ã‚¨ãƒ©ãƒ¼ãŒè¨±å®¹ç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
            is_valid = error_x <= 1.0 and error_y <= 1.0
            
            if not is_valid:
                st.warning(f"åº§æ¨™å¤‰æ›ã®èª¤å·®ãŒå¤§ãã„ã§ã™: x={error_x:.2f}, y={error_y:.2f}")
            
            return is_valid
            
        except Exception as e:
            st.error(f"åº§æ¨™å¤‰æ›ã®æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return False

class LandmarkAnalyzer:
    """
    ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åˆ†æã¨ä¿¡é ¼åº¦è©•ä¾¡ã®ã‚¯ãƒ©ã‚¹
    """
    
    @staticmethod
    def calculate_group_center(landmarks, group_indices: List[int], image_shape: Tuple[int, int]) -> Optional[Dict[str, float]]:
        """
        è¤‡æ•°ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®é‡å¿ƒã‚’è¨ˆç®—ï¼ˆæ”¹å–„æ¡ˆ1: è¤‡æ•°ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®å¹³å‡åŒ–ï¼‰
        
        Args:
            landmarks: MediaPipeãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            group_indices: å¹³å‡åŒ–ã™ã‚‹ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆ
            image_shape: ç”»åƒã‚µã‚¤ã‚º (height, width)
            
        Returns:
            é‡å¿ƒåº§æ¨™ {'x': float, 'y': float} ã¾ãŸã¯ None
        """
        if not landmarks or not group_indices:
            return None
        
        h, w = image_shape[:2]
        valid_points = []
        
        for idx in group_indices:
            if idx < len(landmarks.landmark):
                point = landmarks.landmark[idx]
                valid_points.append({
                    'x': point.x * w,
                    'y': point.y * h
                })
        
        if not valid_points:
            return None
        
        # é‡å¿ƒè¨ˆç®—
        center_x = sum(p['x'] for p in valid_points) / len(valid_points)
        center_y = sum(p['y'] for p in valid_points) / len(valid_points)
        
        return {'x': center_x, 'y': center_y}
    
    @staticmethod
    def assess_landmark_confidence(landmarks, point_name: str, image_shape: Tuple[int, int, int]) -> Dict[str, Any]:
        """
        ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ä¿¡é ¼åº¦ã‚’è©•ä¾¡ï¼ˆæ”¹å–„æ¡ˆ4: ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã«ã‚ˆã‚‹ä¿¡é ¼åº¦å¯è¦–åŒ–ï¼‰
        
        Args:
            landmarks: MediaPipeãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            point_name: ç‰¹å¾´ç‚¹å
            image_shape: ç”»åƒã‚µã‚¤ã‚º (height, width, channels)
            
        Returns:
            ä¿¡é ¼åº¦æƒ…å ±ã®è¾æ›¸
        """
        if point_name not in AppConfig.LANDMARK_GROUPS:
            return {'confidence': 0.0, 'status': 'unknown', 'color': '#808080'}
        
        group_indices = AppConfig.LANDMARK_GROUPS[point_name]
        h, w = image_shape[:2]  # ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã‚’é™¤å¤–
        
        # å„ç‚¹ã®åº§æ¨™ã‚’å–å¾—
        points = []
        for idx in group_indices:
            if idx < len(landmarks.landmark):
                point = landmarks.landmark[idx]
                points.append({
                    'x': point.x * w,
                    'y': point.y * h,
                    'z': point.z  # æ·±åº¦æƒ…å ±ã‚‚è€ƒæ…®
                })
        
        if len(points) < 2:
            return {'confidence': 0.0, 'status': 'insufficient_points', 'color': '#FF0000'}
        
        # ç‚¹ç¾¤ã®åˆ†æ•£ã‹ã‚‰ä¿¡é ¼åº¦ã‚’è¨ˆç®—
        center = LandmarkAnalyzer.calculate_group_center(landmarks, group_indices, (h, w))
        if not center:
            return {'confidence': 0.0, 'status': 'calculation_failed', 'color': '#FF0000'}
        
        # å„ç‚¹ã®ä¸­å¿ƒã‹ã‚‰ã®è·é›¢ã®åˆ†æ•£ã‚’è¨ˆç®—
        distances = []
        for point in points:
            dist = math.sqrt((point['x'] - center['x'])**2 + (point['y'] - center['y'])**2)
            distances.append(dist)
        
        # åˆ†æ•£ãŒå°ã•ã„ã»ã©ä¿¡é ¼åº¦ãŒé«˜ã„
        variance = np.var(distances) if distances else float('inf')
        confidence = max(0.0, min(1.0, 1.0 / (1.0 + variance / 10.0)))
        
        # ä¿¡é ¼åº¦ã«åŸºã¥ãè‰²ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
        if confidence > 0.8:
            status, color = 'high', '#00FF00'
        elif confidence > 0.5:
            status, color = 'medium', '#FFAA00'
        else:
            status, color = 'low', '#FF0000'
        
        return {
            'confidence': confidence,
            'status': status,
            'color': color,
            'variance': variance,
            'point_count': len(points)
        }
    
    @staticmethod
    def validate_anatomical_constraints(nose_tip: Dict[str, float], 
                                      nose_bridge: Dict[str, float],
                                      left_nostril: Dict[str, float],
                                      right_nostril: Dict[str, float]) -> Dict[str, Any]:
        """
        è§£å‰–å­¦çš„åˆ¶ç´„ã®æ¤œè¨¼ï¼ˆæ”¹å–„æ¡ˆ5: è£œæ­£å¼ã®å°å…¥ï¼‰
        
        Args:
            nose_tip, nose_bridge, left_nostril, right_nostril: å„ç‰¹å¾´ç‚¹ã®åº§æ¨™
            
        Returns:
            æ¤œè¨¼çµæœã®è¾æ›¸
        """
        warnings = []
        
        # é¼»å…ˆã¨é¼»æ¢ã®è·é›¢ãƒã‚§ãƒƒã‚¯
        nose_length = math.sqrt((nose_tip['x'] - nose_bridge['x'])**2 + 
                               (nose_tip['y'] - nose_bridge['y'])**2)
        
        # å°é¼»é–“ã®è·é›¢ãƒã‚§ãƒƒã‚¯
        nostril_distance = math.sqrt((left_nostril['x'] - right_nostril['x'])**2 + 
                                   (left_nostril['y'] - right_nostril['y'])**2)
        
        # é¼»ã®è§’åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆå‚ç›´ã‹ã‚‰ã®å‚¾ãï¼‰
        nose_angle = math.atan2(nose_tip['x'] - nose_bridge['x'], 
                               nose_tip['y'] - nose_bridge['y'])
        nose_angle_degrees = abs(math.degrees(nose_angle))
        
        # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
        if nose_length < 10:
            warnings.append("é¼»ã®é•·ã•ãŒçŸ­ã™ãã¾ã™")
        elif nose_length > 200:
            warnings.append("é¼»ã®é•·ã•ãŒé•·ã™ãã¾ã™")
        
        if nostril_distance < 5:
            warnings.append("å°é¼»é–“ã®è·é›¢ãŒè¿‘ã™ãã¾ã™")
        elif nostril_distance > 100:
            warnings.append("å°é¼»é–“ã®è·é›¢ãŒé ã™ãã¾ã™")
        
        if nose_angle_degrees > 30:
            warnings.append(f"é¼»ã®è§’åº¦ãŒä¸è‡ªç„¶ã§ã™ï¼ˆ{nose_angle_degrees:.1f}åº¦ï¼‰")
        
        return {
            'is_valid': len(warnings) == 0,
            'warnings': warnings,
            'metrics': {
                'nose_length': nose_length,
                'nostril_distance': nostril_distance,
                'nose_angle_degrees': nose_angle_degrees
            }
        }

class FaceDetector:
    """é¡”æ¤œå‡ºã¨ç‰¹å¾´ç‚¹æŠ½å‡ºã‚’è¡Œã†ã‚¯ãƒ©ã‚¹ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    
    def __init__(self):
        """
        FaceDetectorã‚’åˆæœŸåŒ–
        
        MediaPipeã®è¨­å®šã‚’æœ€é©åŒ–ã—ã€æ¤œå‡ºç²¾åº¦ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚
        """
        self.face_mesh = mp_face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=2,
            refine_landmarks=True,
            min_detection_confidence=0.5
        )
        self.landmark_analyzer = LandmarkAnalyzer()
    
    def detect_face_landmarks(self, image: np.ndarray) -> Tuple[Optional[Any], Optional[str]]:
        """
        é¡”ã®ç‰¹å¾´ç‚¹ã‚’æ¤œå‡ºã—ã€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™ï¼ˆæ”¹å–„ç‰ˆï¼‰
        
        Args:
            image: å…¥åŠ›ç”»åƒï¼ˆOpenCVå½¢å¼ï¼‰
            
        Returns:
            (landmarks, error_message): ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã¨ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¿ãƒ—ãƒ«
        """
        try:
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = self.face_mesh.process(rgb_image)
            
            if not results.multi_face_landmarks:
                return None, "é¡”ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š\nâ€¢ é¡”ãŒæ­£é¢ã‚’å‘ã„ã¦ã„ã‚‹ã‹\nâ€¢ é¡”ãŒç”»åƒã®ä¸­å¤®ã«ã‚ã‚‹ã‹\nâ€¢ ç…§æ˜ãŒé©åˆ‡ã‹"
            
            if len(results.multi_face_landmarks) > 1:
                return None, "è¤‡æ•°ã®é¡”ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚é¡”ãŒä¸€ã¤ã ã‘å†™ã£ã¦ã„ã‚‹ç”»åƒã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
            
            return results.multi_face_landmarks[0], None
            
        except Exception as e:
            return None, f"é¡”æ¤œå‡ºå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
    
    def get_enhanced_landmarks(self, landmarks, image_shape: Tuple[int, int, int]) -> Dict[str, Dict[str, float]]:
        """
        å¼·åŒ–ã•ã‚ŒãŸãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ã‚’å–å¾—ï¼ˆè¤‡æ•°ç‚¹ã®å¹³å‡åŒ–é©ç”¨ï¼‰
        
        Args:
            landmarks: MediaPipeãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            image_shape: ç”»åƒã‚µã‚¤ã‚º (height, width, channels)
            
        Returns:
            ç‰¹å¾´ç‚¹åã‚’ã‚­ãƒ¼ã¨ã™ã‚‹åº§æ¨™è¾æ›¸
        """
        # image_shapeã‹ã‚‰å¿…è¦ãªéƒ¨åˆ†ã ã‘ã‚’å–ã‚Šå‡ºã™
        h, w = image_shape[:2]
        return self._get_enhanced_landmarks_internal(landmarks, (h, w))
    
    def _get_enhanced_landmarks_internal(self, landmarks, image_shape: Tuple[int, int]) -> Dict[str, Dict[str, float]]:
        """
        å†…éƒ¨ç”¨ã®å¼·åŒ–ã•ã‚ŒãŸãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™å–å¾—ãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            landmarks: MediaPipeãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            image_shape: ç”»åƒã‚µã‚¤ã‚º (height, width)
            
        Returns:
            ç‰¹å¾´ç‚¹åã‚’ã‚­ãƒ¼ã¨ã™ã‚‹åº§æ¨™è¾æ›¸
        """
        enhanced_coords = {}
        
        for point_name, group_indices in AppConfig.LANDMARK_GROUPS.items():
            # è¤‡æ•°ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®å¹³å‡åŒ–
            center = self.landmark_analyzer.calculate_group_center(
                landmarks, group_indices, image_shape
            )
            if center:
                enhanced_coords[point_name] = center
        
        return enhanced_coords
    
    def draw_landmarks_with_confidence(self, image: np.ndarray, landmarks, show_confidence: bool = False) -> np.ndarray:
        """
        ä¿¡é ¼åº¦æƒ…å ±ä»˜ãã§ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æç”»
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            landmarks: MediaPipeãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            show_confidence: ä¿¡é ¼åº¦æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ã‹ã©ã†ã‹
            
        Returns:
            æ³¨é‡ˆä»˜ãç”»åƒ
        """
        annotated_image = image.copy()
        h, w = image.shape[:2]
        
        # åŸºæœ¬çš„ãªç‰¹å¾´ç‚¹æç”»
        mp_drawing.draw_landmarks(
            image=annotated_image,
            landmark_list=landmarks,
            connections=mp_face_mesh.FACEMESH_CONTOURS,
            landmark_drawing_spec=None,
            connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()
        )
        
        # å¼·åŒ–ã•ã‚ŒãŸãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’é‡ã­æã
        if show_confidence:
            enhanced_landmarks = self.get_enhanced_landmarks(landmarks, image.shape)
            
            for point_name, coords in enhanced_landmarks.items():
                confidence_info = self.landmark_analyzer.assess_landmark_confidence(
                    landmarks, point_name, image.shape
                )
                
                x, y = int(coords['x']), int(coords['y'])
                
                # ä¿¡é ¼åº¦ã«åŸºã¥ãè‰²ã§å††ã‚’æç”»
                color_hex = confidence_info['color']
                color_bgr = tuple(int(color_hex[i:i+2], 16) for i in (5, 3, 1))  # BGRå½¢å¼ã«å¤‰æ›
                
                # ä¿¡é ¼åº¦ã«åŸºã¥ãã‚µã‚¤ã‚º
                radius = int(8 + confidence_info['confidence'] * 8)
                cv2.circle(annotated_image, (x, y), radius, color_bgr, -1)
                cv2.circle(annotated_image, (x, y), radius + 2, (255, 255, 255), 2)
                
                # ä¿¡é ¼åº¦ãƒ†ã‚­ã‚¹ãƒˆ
                confidence_text = f"{confidence_info['confidence']:.2f}"
                cv2.putText(annotated_image, confidence_text, (x + 15, y - 5),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        return annotated_image
    
    def adjust_landmarks(self, landmarks, adjustments: Dict[str, Dict[str, float]], image_shape: Tuple[int, int]):
        """
        ç‰¹å¾´ç‚¹ã®åº§æ¨™ã‚’æ‰‹å‹•èª¿æ•´ï¼ˆé«˜ç²¾åº¦ç‰ˆï¼‰
        
        Args:
            landmarks: å…ƒã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            adjustments: èª¿æ•´å€¤ã®è¾æ›¸
            image_shape: ç”»åƒã‚µã‚¤ã‚º
            
        Returns:
            èª¿æ•´æ¸ˆã¿ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
        """
        adjusted_landmarks = copy.deepcopy(landmarks)
        h, w = image_shape[:2]
        
        # å¼·åŒ–ã•ã‚ŒãŸãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ä»£è¡¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
        point_indices = {
            'nose_tip': 1,
            'nose_bridge': 6,
            'left_nostril': 131,
            'right_nostril': 102,
            'left_eye_center': 159,
            'right_eye_center': 386
        }
        
        for point_name, coords in adjustments.items():
            if point_name in point_indices:
                idx = point_indices[point_name]
                if idx < len(adjusted_landmarks.landmark):
                    # é«˜ç²¾åº¦ã§æ­£è¦åŒ–åº§æ¨™ã«å¤‰æ›
                    adjusted_landmarks.landmark[idx].x = coords['x'] / w
                    adjusted_landmarks.landmark[idx].y = coords['y'] / h
        
        return adjusted_landmarks

@st.cache_resource
def get_face_detector() -> FaceDetector:
    """
    FaceDetectorã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¿”ã™
    
    Returns:
        FaceDetectorã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    return FaceDetector()

def load_image_from_uploaded_file(uploaded_file) -> Tuple[Optional[np.ndarray], Optional[Image.Image]]:
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç”»åƒã‚’èª­ã¿è¾¼ã‚€ï¼ˆæ”¹å–„ç‰ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼‰
    
    Args:
        uploaded_file: Streamlitã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        
    Returns:
        (cv2_image, pil_image): OpenCVå½¢å¼ã¨PILå½¢å¼ã®ç”»åƒã‚¿ãƒ—ãƒ«
    """
    if uploaded_file is None:
        return None, None
    
    try:
        pil_image = Image.open(uploaded_file)
        
        # RGBAã‚’RGBã«å¤‰æ›
        if pil_image.mode == 'RGBA':
            pil_image = pil_image.convert('RGB')
        elif pil_image.mode == 'L':  # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«
            pil_image = pil_image.convert('RGB')
        
        image_array = np.array(pil_image)
        cv2_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)
        
        return cv2_image, pil_image
        
    except UnidentifiedImageError:
        st.error("âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ç”»åƒå½¢å¼ã§ã™ã€‚JPGã€PNGã€ã¾ãŸã¯BMPå½¢å¼ã®ç”»åƒã‚’ã”ä½¿ç”¨ãã ã•ã„ã€‚")
        return None, None
    except ValueError as e:
        st.error(f"âŒ ç”»åƒãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None, None
    except MemoryError:
        st.error("âŒ ç”»åƒã®ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ã€‚ã‚ˆã‚Šå°ã•ãªç”»åƒã‚’ãŠè©¦ã—ãã ã•ã„ã€‚")
        return None, None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None, None

def calculate_canvas_dimensions(image_shape: Tuple[int, int, int]) -> Tuple[int, int]:
    """
    ç”»åƒã‚µã‚¤ã‚ºã«åŸºã¥ã„ã¦ã‚­ãƒ£ãƒ³ãƒã‚¹ã®é©åˆ‡ãªã‚µã‚¤ã‚ºã‚’è¨ˆç®—
    
    Args:
        image_shape: ç”»åƒã®ã‚·ã‚§ã‚¤ãƒ— (height, width, channels)
        
    Returns:
        (canvas_width, canvas_height): ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚º
    """
    original_h, original_w = image_shape[:2]
    
    # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒã—ãªãŒã‚‰ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚ºã‚’èª¿æ•´
    if original_w > original_h:
        # æ¨ªé•·ã®ç”»åƒ
        canvas_w = CANVAS_WIDTH
        canvas_h = int((original_h / original_w) * CANVAS_WIDTH)
        canvas_h = min(canvas_h, CANVAS_HEIGHT)
    else:
        # ç¸¦é•·ã®ç”»åƒ
        canvas_h = min(CANVAS_HEIGHT, int((original_h / original_w) * CANVAS_WIDTH))
        canvas_w = int((original_w / original_h) * canvas_h)
    
    return canvas_w, canvas_h

def initialize_session_state():
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–ï¼ˆæ”¹å–„ç‰ˆï¼‰
    
    ç”»åƒå¤‰æ›´æ¤œå‡ºã«ã‚ˆã‚‹è‡ªå‹•ã‚¯ãƒªã‚¢æ©Ÿèƒ½ã‚’è¿½åŠ ã—ã€å±¥æ­´ç®¡ç†ã‚’å®Œå…¨å®Ÿè£…
    """
    # ç”»åƒæ“ä½œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    defaults = {
        'eye_distance': 0,
        'nose_position': 0,
        'eye_size': 0,
        'nose_size': 0
    }
    
    for key, default_value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value
    
    # ç‰¹å¾´ç‚¹æ‰‹å‹•èª¿æ•´å€¤ã®ä¸€å…ƒç®¡ç†ï¼ˆé«˜ç²¾åº¦åº§æ¨™ï¼‰
    if 'manual_adjustments' not in st.session_state:
        st.session_state.manual_adjustments = {}
    
    # å±¥æ­´ç®¡ç†ã®å®Œå…¨å®Ÿè£…
    if 'adjustment_history' not in st.session_state:
        st.session_state.adjustment_history = []
    if 'adjustment_redo_stack' not in st.session_state:
        st.session_state.adjustment_redo_stack = []
    
    # UIè¨­å®šã®å‹•çš„ç®¡ç†
    if 'movement_threshold' not in st.session_state:
        st.session_state.movement_threshold = AppConfig.DEFAULT_MOVEMENT_THRESHOLD
    
    # ç”»åƒå¤‰æ›´æ¤œå‡ºã«ã‚ˆã‚‹è‡ªå‹•ã‚¯ãƒªã‚¢
    if 'current_image_hash' not in st.session_state:
        st.session_state.current_image_hash = None
    if 'previous_image_hash' not in st.session_state:
        st.session_state.previous_image_hash = None

def detect_image_change(image_bytes: bytes) -> bool:
    """
    ç”»åƒå¤‰æ›´ã‚’æ¤œå‡ºã—ã€å¿…è¦ã«å¿œã˜ã¦èª¿æ•´å€¤ã‚’ã‚¯ãƒªã‚¢
    
    Args:
        image_bytes: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã®ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿
        
    Returns:
        ç”»åƒãŒå¤‰æ›´ã•ã‚ŒãŸã‹ã©ã†ã‹
    """
    # ç”»åƒã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—
    current_hash = hashlib.md5(image_bytes).hexdigest()
    st.session_state.current_image_hash = current_hash
    
    # ç”»åƒãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆ
    if (st.session_state.previous_image_hash is not None and 
        st.session_state.previous_image_hash != current_hash):
        
        # èª¿æ•´å€¤ã¨å±¥æ­´ã‚’ã‚¯ãƒªã‚¢
        st.session_state.manual_adjustments = {}
        st.session_state.adjustment_history = []
        st.session_state.adjustment_redo_stack = []
        
        st.session_state.previous_image_hash = current_hash
        return True
    
    st.session_state.previous_image_hash = current_hash
    return False

def create_precision_adjustment_controls() -> Dict[str, float]:
    """
    ç²¾å¯†èª¿æ•´ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã‚’ä½œæˆï¼ˆæ”¹å–„æ¡ˆ2: ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼å¾®èª¿æ•´ï¼‰
    
    Returns:
        ç²¾å¯†èª¿æ•´å€¤ã®è¾æ›¸
    """
    st.sidebar.subheader("ğŸ¯ ç²¾å¯†èª¿æ•´")
    
    precision_adjustments = {}
    
    # é¸æŠã•ã‚ŒãŸç‰¹å¾´ç‚¹ã®ç²¾å¯†èª¿æ•´
    if st.session_state.manual_adjustments:
        selected_point = st.sidebar.selectbox(
            "èª¿æ•´ã™ã‚‹ç‰¹å¾´ç‚¹ã‚’é¸æŠ:",
            list(st.session_state.manual_adjustments.keys()),
            format_func=lambda x: {
                'nose_tip': 'ğŸŸ¢ é¼»å…ˆ',
                'nose_bridge': 'ğŸŸ¢ é¼»æ¢', 
                'left_nostril': 'ğŸ”µ å·¦å°é¼»',
                'right_nostril': 'ğŸ”µ å³å°é¼»',
                'left_eye_center': 'ğŸ”´ å·¦ç›®',
                'right_eye_center': 'ğŸ”´ å³ç›®'
            }.get(x, x)
        )
        
        if selected_point:
            current_coords = st.session_state.manual_adjustments[selected_point]
            
            # Xåº§æ¨™ã®å¾®èª¿æ•´
            x_offset = st.sidebar.slider(
                "Xåº§æ¨™ã‚ªãƒ•ã‚»ãƒƒãƒˆ",
                min_value=-20.0,
                max_value=20.0,
                value=0.0,
                step=0.1,
                key=f"{selected_point}_x_offset"
            )
            
            # Yåº§æ¨™ã®å¾®èª¿æ•´
            y_offset = st.sidebar.slider(
                "Yåº§æ¨™ã‚ªãƒ•ã‚»ãƒƒãƒˆ", 
                min_value=-20.0,
                max_value=20.0,
                value=0.0,
                step=0.1,
                key=f"{selected_point}_y_offset"
            )
            
            # èª¿æ•´å€¤ã‚’é©ç”¨
            if x_offset != 0.0 or y_offset != 0.0:
                adjusted_coords = {
                    'x': current_coords['x'] + x_offset,
                    'y': current_coords['y'] + y_offset
                }
                precision_adjustments[selected_point] = adjusted_coords
                
                # é©ç”¨ãƒœã‚¿ãƒ³
                if st.sidebar.button("ğŸ”§ ç²¾å¯†èª¿æ•´ã‚’é©ç”¨"):
                    st.session_state.manual_adjustments[selected_point] = adjusted_coords
                    # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
                    st.session_state[f"{selected_point}_x_offset"] = 0.0
                    st.session_state[f"{selected_point}_y_offset"] = 0.0
                    st.rerun()
    
    return precision_adjustments

def create_enhanced_landmark_adjustment_controls() -> bool:
    """
    å¼·åŒ–ã•ã‚ŒãŸç‰¹å¾´ç‚¹èª¿æ•´ã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«UIã‚’ä½œæˆ
    
    Returns:
        èª¿æ•´æ©Ÿèƒ½ãŒæœ‰åŠ¹ã‹ã©ã†ã‹
    """
    st.sidebar.subheader("ğŸ¯ ç‰¹å¾´ç‚¹ãƒ‰ãƒ©ãƒƒã‚°èª¿æ•´")
    
    # èª¿æ•´æ©Ÿèƒ½ã®æœ‰åŠ¹åŒ–ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
    enable_adjustment = st.sidebar.checkbox("ç‰¹å¾´ç‚¹èª¿æ•´ã‚’æœ‰åŠ¹åŒ–")
    
    if enable_adjustment:
        st.sidebar.info("ğŸ’¡ å·¦ã®ç”»åƒä¸Šã§è‰²ä»˜ãã®ç‚¹ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã—ã¦ç‰¹å¾´ç‚¹ã‚’èª¿æ•´ã§ãã¾ã™")
        
        # ç§»å‹•æ¤œå‡ºé–¾å€¤ã®è¨­å®š
        st.session_state.movement_threshold = st.sidebar.slider(
            "ç§»å‹•æ¤œå‡ºé–¾å€¤ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰",
            min_value=1.0,
            max_value=20.0,
            value=st.session_state.movement_threshold,
            step=0.5
        )
        
        # ç²¾å¯†èª¿æ•´ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«
        precision_adjustments = create_precision_adjustment_controls()
        
        # æ“ä½œæ–¹æ³•ã®èª¬æ˜
        st.sidebar.markdown("""
        **æ“ä½œæ–¹æ³•:**
        - ğŸ–±ï¸ è‰²ä»˜ãã®å††ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã—ã¦ç§»å‹•
        - ğŸ¯ ç²¾å¯†èª¿æ•´ã§ãƒ”ã‚¯ã‚»ãƒ«å˜ä½ã®å¾®èª¿æ•´
        - ğŸ“Š ä¿¡é ¼åº¦è¡¨ç¤ºã§æ¤œå‡ºå“è³ªã‚’ç¢ºèª
        - ğŸ”„ ãƒªã‚»ãƒƒãƒˆã§åˆæœŸçŠ¶æ…‹ã«å¾©å¸°
        
        **ç‰¹å¾´ç‚¹ã®è­˜åˆ¥:**
        - ğŸŸ¢ å¤§=é¼»å…ˆ, å°=é¼»æ¢
        - ğŸ”µ æ¿ƒã„é’=å·¦å°é¼», æ˜ã‚‹ã„é’=å³å°é¼»  
        - ğŸ”´ æ¿ƒã„èµ¤=å·¦ç›®, ã‚ªãƒ¬ãƒ³ã‚¸=å³ç›®
        """)
        
        # æ“ä½œãƒœã‚¿ãƒ³
        col1, col2 = st.sidebar.columns(2)
        
        with col1:
            if st.button("ğŸ”„ ã™ã¹ã¦ãƒªã‚»ãƒƒãƒˆ"):
                st.session_state.manual_adjustments = {}
                st.session_state.adjustment_history = []
                st.session_state.adjustment_redo_stack = []
                st.rerun()
        
        with col2:
            # å…ƒã«æˆ»ã™æ©Ÿèƒ½
            can_undo = len(st.session_state.adjustment_history) > 0
            if st.button("â†¶ å…ƒã«æˆ»ã™", disabled=not can_undo):
                if undo_last_adjustment():
                    st.rerun()
        
        # ç¾åœ¨ã®èª¿æ•´çŠ¶æ³è¡¨ç¤º
        if st.session_state.manual_adjustments:
            st.sidebar.success(f"ğŸ“ {len(st.session_state.manual_adjustments)}å€‹ã®ç‰¹å¾´ç‚¹ãŒèª¿æ•´æ¸ˆã¿")
            
            # èª¿æ•´è©³ç´°ã‚’è¡¨ç¤º
            with st.sidebar.expander("ğŸ“ èª¿æ•´è©³ç´°"):
                for point_name, coords in st.session_state.manual_adjustments.items():
                    label_map = {
                        'nose_tip': 'ğŸŸ¢ é¼»å…ˆ', 'nose_bridge': 'ğŸŸ¢ é¼»æ¢',
                        'left_nostril': 'ğŸ”µ å·¦å°é¼»', 'right_nostril': 'ğŸ”µ å³å°é¼»',
                        'left_eye_center': 'ğŸ”´ å·¦ç›®', 'right_eye_center': 'ğŸ”´ å³ç›®'
                    }
                    point_label = label_map.get(point_name, point_name)
                    st.write(f"**{point_label}**: ({coords['x']:.1f}, {coords['y']:.1f})")
        else:
            st.sidebar.info("ğŸ“ èª¿æ•´ã•ã‚ŒãŸç‰¹å¾´ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«é›†ç´„
        with st.sidebar.expander("ğŸ”§ æŠ€è¡“æƒ…å ±"):
            st.write("**åŒæ–¹å‘ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼:** æœ‰åŠ¹")
            st.write(f"**ç§»å‹•æ¤œå‡ºé–¾å€¤:** {st.session_state.movement_threshold}ãƒ”ã‚¯ã‚»ãƒ«")
            st.write("**åº§æ¨™ç³»:** é«˜ç²¾åº¦æµ®å‹•å°æ•°ç‚¹")
            if st.session_state.manual_adjustments:
                st.write("**ç¾åœ¨ã®èª¿æ•´å€¤:**")
                st.json(st.session_state.manual_adjustments)
            else:
                st.write("**çŠ¶æ…‹:** åˆæœŸçŠ¶æ…‹")
    
    return enable_adjustment

def undo_last_adjustment() -> bool:
    """
    æœ€å¾Œã®èª¿æ•´æ“ä½œã‚’å…ƒã«æˆ»ã™ï¼ˆæ”¹å–„ç‰ˆï¼‰
    
    Returns:
        å…ƒã«æˆ»ã™æ“ä½œãŒæˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    if not st.session_state.adjustment_history:
        return False
    
    # ç¾åœ¨ã®çŠ¶æ…‹ã‚’Redoå±¥æ­´ã«ä¿å­˜
    current_state = copy.deepcopy(st.session_state.manual_adjustments)
    st.session_state.adjustment_redo_stack.append(current_state)
    
    # æœ€å¤§Redoå±¥æ­´æ•°ã®åˆ¶é™
    if len(st.session_state.adjustment_redo_stack) > AppConfig.MAX_HISTORY_SIZE:
        st.session_state.adjustment_redo_stack.pop(0)
    
    # æœ€å¾Œã®çŠ¶æ…‹ã‚’å¾©å…ƒ
    previous_state = st.session_state.adjustment_history.pop()
    st.session_state.manual_adjustments = previous_state
    
    return True

def create_enhanced_interactive_canvas(landmarks, image_shape: Tuple[int, int, int], pil_image: Image.Image):
    """
    å¼·åŒ–ã•ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªç‰¹å¾´ç‚¹èª¿æ•´ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚’ä½œæˆ
    
    Args:
        landmarks: MediaPipeãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
        image_shape: ç”»åƒã‚µã‚¤ã‚º
        pil_image: PILç”»åƒ
        
    Returns:
        èª¿æ•´ã•ã‚ŒãŸç‰¹å¾´ç‚¹ã®è¾æ›¸
    """
    if landmarks is None:
        st.warning("ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return None
    
    try:
        # ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚ºã¨å®Ÿéš›ã®ã‚µã‚¤ã‚º
        canvas_w, canvas_h = calculate_canvas_dimensions(image_shape)
        real_w, real_h = image_shape[1], image_shape[0]  # OpenCVå½¢å¼ (h, w) â†’ (w, h)
        
        # ç”»åƒã‚’ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
        canvas_image = pil_image.resize((canvas_w, canvas_h), Image.Resampling.LANCZOS)
        
        # åº§æ¨™å¤‰æ›ã®æ•´åˆæ€§ã‚’æ¤œè¨¼
        test_coords = {'x': 100.0, 'y': 100.0}
        is_conversion_valid = CoordinateConverter.verify_conversion_integrity(
            test_coords, (real_w, real_h), (canvas_w, canvas_h)
        )
        
        if not is_conversion_valid:
            st.warning("âš ï¸ åº§æ¨™å¤‰æ›ã®ç²¾åº¦ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚çµæœãŒä¸æ­£ç¢ºã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        
        # å¼·åŒ–ã•ã‚ŒãŸãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’å–å¾—
        detector = get_face_detector()
        enhanced_landmarks = detector.get_enhanced_landmarks(landmarks, image_shape)
        
        # é‡è¦ãªç‰¹å¾´ç‚¹ã®å®šç¾©ï¼ˆä¿¡é ¼åº¦ã«åŸºã¥ãè‰²ä»˜ã‘ï¼‰
        key_points = {}
        base_config = {
            'nose_tip': {'label': 'é¼»å…ˆ', 'base_color': '#00FF00', 'radius': 12},
            'nose_bridge': {'label': 'é¼»æ¢', 'base_color': '#00AA00', 'radius': 8},
            'left_nostril': {'label': 'å·¦å°é¼»', 'base_color': '#0000FF', 'radius': 10},
            'right_nostril': {'label': 'å³å°é¼»', 'base_color': '#0066FF', 'radius': 10},
            'left_eye_center': {'label': 'å·¦ç›®ä¸­å¿ƒ', 'base_color': '#FF0000', 'radius': 10},
            'right_eye_center': {'label': 'å³ç›®ä¸­å¿ƒ', 'base_color': '#FF6600', 'radius': 10}
        }
        
        # ä¿¡é ¼åº¦ã«åŸºã¥ãè‰²ã¨ã‚µã‚¤ã‚ºã®èª¿æ•´
        for point_name, config in base_config.items():
            if point_name in enhanced_landmarks:
                confidence_info = LandmarkAnalyzer.assess_landmark_confidence(
                    landmarks, point_name, image_shape
                )
                
                key_points[point_name] = {
                    'coords': enhanced_landmarks[point_name],
                    'label': config['label'],
                    'color': confidence_info['color'],
                    'radius': config['radius'],
                    'confidence': confidence_info['confidence']
                }
        
        # åˆæœŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç”Ÿæˆ
        initial_objects = []
        for point_name, point_info in key_points.items():
            real_coords = point_info['coords']
            
            # æ‰‹å‹•èª¿æ•´ãŒã‚ã‚Œã°é©ç”¨
            if point_name in st.session_state.manual_adjustments:
                real_coords = st.session_state.manual_adjustments[point_name]
            
            # ã‚­ãƒ£ãƒ³ãƒã‚¹åº§æ¨™ã«å¤‰æ›ï¼ˆé«˜ç²¾åº¦ï¼‰
            canvas_coords = CoordinateConverter.scale_to_canvas(
                real_coords, (real_w, real_h), (canvas_w, canvas_h)
            )
            
            # èª¿æ•´å¯èƒ½ãªå††ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            initial_objects.append({
                'type': 'circle',
                'left': canvas_coords['x'] - point_info['radius'],
                'top': canvas_coords['y'] - point_info['radius'],
                'radius': point_info['radius'],
                'fill': point_info['color'],
                'stroke': '#FFFFFF',
                'strokeWidth': 2,
                'selectable': True,
                'name': point_name,
                'originalX': canvas_coords['x'],
                'originalY': canvas_coords['y'],
                'confidence': point_info['confidence']
            })
        
        # ç‰¹å¾´ç‚¹ã®å‡¡ä¾‹ã‚’è¡¨ç¤ºï¼ˆä¿¡é ¼åº¦æƒ…å ±ä»˜ãï¼‰
        st.caption("**ç‰¹å¾´ç‚¹:** ğŸŸ¢=é¼» ğŸ”µ=å°é¼» ğŸ”´=ç›® | è‰²ã®æ¿ƒã•=æ¤œå‡ºä¿¡é ¼åº¦")
        
        # ã‚­ãƒ£ãƒ³ãƒã‚¹ã®ä½œæˆï¼ˆæ”¹å–„ç‰ˆï¼‰
        canvas_result = st_canvas(
            fill_color="rgba(255, 165, 0, 0.3)",
            stroke_width=2,
            stroke_color="#FFFFFF",
            background_image=canvas_image,
            update_streamlit=True,
            height=canvas_h,
            width=canvas_w,
            drawing_mode="transform",
            initial_drawing={
                "version": "4.4.0",
                "objects": initial_objects
            },
            key="enhanced_landmark_canvas",
            # ä»¥ä¸‹ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
            display_toolbar=True,
            key_down_callback=None,
            key_up_callback=None,
            mouse_down_callback=None,
            mouse_up_callback=None,
            mouse_move_callback=None
        )
        
        # ã‚­ãƒ£ãƒ³ãƒã‚¹æ“ä½œçµæœã®å‡¦ç†ï¼ˆé«˜ç²¾åº¦ç‰ˆï¼‰
        if canvas_result.json_data is not None:
            update_enhanced_landmark_positions(
                canvas_result, key_points, (real_w, real_h), (canvas_w, canvas_h)
            )
        
        return st.session_state.manual_adjustments
        
    except Exception as e:
        st.error(f"ã‚­ãƒ£ãƒ³ãƒã‚¹ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

def update_enhanced_landmark_positions(canvas_result, key_points: Dict, 
                                     real_size: Tuple[int, int], 
                                     canvas_size: Tuple[int, int]) -> bool:
    """
    ã‚­ãƒ£ãƒ³ãƒã‚¹çµæœã‹ã‚‰ç‰¹å¾´ç‚¹ä½ç½®ã‚’æ›´æ–°ï¼ˆé«˜ç²¾åº¦ç‰ˆï¼‰
    
    Args:
        canvas_result: st_canvasã‹ã‚‰è¿”ã•ã‚Œã‚‹ã‚­ãƒ£ãƒ³ãƒã‚¹æ“ä½œçµæœ
        key_points: ç‰¹å¾´ç‚¹ã®å®šç¾©è¾æ›¸
        real_size: å®Ÿéš›ã®ç”»åƒã‚µã‚¤ã‚º (width, height)
        canvas_size: ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚º (width, height)
        
    Returns:
        ä½ç½®ãŒæ›´æ–°ã•ã‚ŒãŸã‹ã©ã†ã‹
    """
    if canvas_result.json_data is None:
        st.warning("ã‚­ãƒ£ãƒ³ãƒã‚¹ã®ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return False
    
    try:
        objects = canvas_result.json_data.get("objects", [])
        movement_threshold = st.session_state.movement_threshold
        
        updated_positions = {}
        state_changed = False
        
        for obj in objects:
            if (obj.get("type") == "circle" and 
                obj.get("name") and 
                obj["name"] in key_points):
                
                point_name = obj["name"]
                
                # ã‚­ãƒ£ãƒ³ãƒã‚¹ä¸Šã®ç¾åœ¨ã®ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—ï¼ˆæµ®å‹•å°æ•°ç‚¹ï¼‰
                current_center_x = obj.get("left", 0.0) + obj.get("radius", 0.0)
                current_center_y = obj.get("top", 0.0) + obj.get("radius", 0.0)
                
                # å…ƒã®ä¸­å¿ƒåº§æ¨™ã‚’å–å¾—
                original_center_x = obj.get("originalX", current_center_x)
                original_center_y = obj.get("originalY", current_center_y)
                
                # ç§»å‹•è·é›¢ã‚’è¨ˆç®—ï¼ˆé«˜ç²¾åº¦ï¼‰
                move_distance = math.sqrt(
                    (current_center_x - original_center_x)**2 + 
                    (current_center_y - original_center_y)**2
                )
                
                # ç§»å‹•æ¤œå‡º
                if move_distance >= movement_threshold:
                    # å®Ÿéš›ã®ç”»åƒåº§æ¨™ã«å¤‰æ›ï¼ˆé«˜ç²¾åº¦ï¼‰
                    real_coords = CoordinateConverter.scale_to_real(
                        {'x': current_center_x, 'y': current_center_y},
                        real_size, canvas_size
                    )
                    
                    # ç¾åœ¨ã®çŠ¶æ…‹ã¨æ¯”è¼ƒã—ã¦å¤‰æ›´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    current_coords = st.session_state.manual_adjustments.get(point_name)
                    if (current_coords is None or 
                        abs(current_coords['x'] - real_coords['x']) > 0.5 or 
                        abs(current_coords['y'] - real_coords['y']) > 0.5):
                        
                        updated_positions[point_name] = real_coords
                        state_changed = True
        
        # çŠ¶æ…‹ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã¯å±¥æ­´ã«ä¿å­˜ã—ã¦ã‹ã‚‰æ›´æ–°
        if state_changed:
            # å±¥æ­´ä¿å­˜
            save_adjustment_to_history()
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
            for point_name, coords in updated_positions.items():
                st.session_state.manual_adjustments[point_name] = coords
            
            # å†æç”»
            st.rerun()
        
        return state_changed
        
    except Exception as e:
        st.error(f"ç‰¹å¾´ç‚¹ä½ç½®æ›´æ–°ã‚¨ãƒ©ãƒ¼: {str(e)}")
        # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        st.error("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:")
        st.error(f"key_points: {key_points}")
        st.error(f"real_size: {real_size}")
        st.error(f"canvas_size: {canvas_size}")
        return False

def save_adjustment_to_history():
    """ç¾åœ¨ã®èª¿æ•´çŠ¶æ…‹ã‚’å±¥æ­´ã«ä¿å­˜ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    # ç¾åœ¨ã®çŠ¶æ…‹ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
    current_state = copy.deepcopy(st.session_state.manual_adjustments)
    
    # ç›´å‰ã®çŠ¶æ…‹ã¨åŒã˜å ´åˆã¯ä¿å­˜ã—ãªã„ï¼ˆé‡è¤‡é™¤å¤–ï¼‰
    if (st.session_state.adjustment_history and 
        st.session_state.adjustment_history[-1] == current_state):
        return
    
    # Redoå±¥æ­´ã‚’ã‚¯ãƒªã‚¢ï¼ˆæ–°ã—ã„æ“ä½œãŒè¡Œã‚ã‚ŒãŸãŸã‚ï¼‰
    st.session_state.adjustment_redo_stack = []
    
    # å±¥æ­´ã«è¿½åŠ ï¼ˆå‹•çš„æœ€å¤§æ•°ç®¡ç†ï¼‰
    max_history = AppConfig.MAX_HISTORY_SIZE
    if len(st.session_state.adjustment_history) >= max_history:
        st.session_state.adjustment_history.pop(0)  # æœ€å¤ã‚’å‰Šé™¤
    
    st.session_state.adjustment_history.append(current_state)

def validate_anatomical_constraints_ui():
    """è§£å‰–å­¦çš„åˆ¶ç´„ã®æ¤œè¨¼çµæœã‚’UIã«è¡¨ç¤º"""
    adjustments = st.session_state.manual_adjustments
    
    # å¿…è¦ãªç‰¹å¾´ç‚¹ãŒæƒã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    required_points = ['nose_tip', 'nose_bridge', 'left_nostril', 'right_nostril']
    if not all(point in adjustments for point in required_points):
        return
    
    # åˆ¶ç´„æ¤œè¨¼ã®å®Ÿè¡Œ
    validation_result = LandmarkAnalyzer.validate_anatomical_constraints(
        adjustments['nose_tip'],
        adjustments['nose_bridge'], 
        adjustments['left_nostril'],
        adjustments['right_nostril']
    )
    
    # çµæœã®è¡¨ç¤º
    if validation_result['is_valid']:
        st.success("âœ… è§£å‰–å­¦çš„åˆ¶ç´„: æ­£å¸¸ç¯„å›²å†…")
    else:
        st.warning("âš ï¸ è§£å‰–å­¦çš„åˆ¶ç´„ã®è­¦å‘Š:")
        for warning in validation_result['warnings']:
            st.write(f"â€¢ {warning}")
        
        # è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        with st.expander("ğŸ“Š è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹"):
            metrics = validation_result['metrics']
            st.write(f"é¼»ã®é•·ã•: {metrics['nose_length']:.1f}px")
            st.write(f"å°é¼»é–“è·é›¢: {metrics['nostril_distance']:.1f}px")
            st.write(f"é¼»ã®è§’åº¦: {metrics['nose_angle_degrees']:.1f}åº¦")

def create_parameter_controls() -> Dict[str, int]:
    """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ¶å¾¡UIã‚’ä½œæˆï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    st.sidebar.header("ç”»åƒæ“ä½œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
    initialize_session_state()
    
    # å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆä½œæˆ
    parameters = {}
    param_configs = [
        ("ç›®ã®é–“ã®è·é›¢", "eye_distance"),
        ("é¼»ã®å‚ç›´ä½ç½®", "nose_position"),
        ("ç›®ã®ã‚µã‚¤ã‚º", "eye_size"),
        ("é¼»ã®ã‚µã‚¤ã‚º", "nose_size")
    ]
    
    for label, key in param_configs:
        st.sidebar.subheader(label)
        col1, col2 = st.sidebar.columns([3, 1])
        
        with col1:
            value = st.slider(
                label,
                min_value=-50,
                max_value=50,
                value=st.session_state[key],
                key=f"{key}_slider",
                label_visibility="collapsed"
            )
        
        with col2:
            value = st.number_input(
                "å€¤",
                min_value=-50,
                max_value=50,
                value=st.session_state[key],
                key=f"{key}_input",
                label_visibility="collapsed"
            )
        
        parameters[key] = value
        st.session_state[key] = value
    
    # æ“ä½œãƒœã‚¿ãƒ³
    st.sidebar.subheader("æ“ä½œ")
    col1, col2 = st.sidebar.columns(2)
    
    with col1:
        if st.button("ãƒªã‚»ãƒƒãƒˆ"):
            # å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’0ã«ãƒªã‚»ãƒƒãƒˆ
            for key in ['eye_distance', 'nose_position', 'eye_size', 'nose_size']:
                st.session_state[key] = 0
            st.rerun()
    
    with col2:
        # ãƒ—ãƒªã‚»ãƒƒãƒˆæ©Ÿèƒ½
        if st.button("ãƒ—ãƒªã‚»ãƒƒãƒˆ"):
            # ã‚ˆãä½¿ã‚ã‚Œã‚‹è¨­å®šå€¤
            st.session_state['eye_distance'] = 5
            st.session_state['nose_position'] = -2
            st.session_state['eye_size'] = 3
            st.session_state['nose_size'] = 1
            st.rerun()
    
    return parameters

def display_parameter_metrics(parameters: Dict[str, int]):
    """ç¾åœ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    st.subheader("ç¾åœ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    cols = st.columns(4)
    
    param_labels = [
        ("ç›®ã®é–“ã®è·é›¢", "eye_distance"),
        ("é¼»ã®å‚ç›´ä½ç½®", "nose_position"),
        ("ç›®ã®ã‚µã‚¤ã‚º", "eye_size"),
        ("é¼»ã®ã‚µã‚¤ã‚º", "nose_size")
    ]
    
    for i, (label, key) in enumerate(param_labels):
        with cols[i]:
            value = parameters[key]
            delta_color = "normal"
            if value > 0:
                delta_color = "normal"
            elif value < 0:
                delta_color = "inverse"
            
            st.metric(
                label, 
                f"{value:+d}%",
                delta=f"{abs(value)}%å¤‰åŒ–" if value != 0 else "å¤‰åŒ–ãªã—"
            )

def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆæ”¹å–„ç‰ˆï¼‰
    
    ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å…¨ä½“çš„ãªæµã‚Œã‚’åˆ¶å¾¡ã—ã€
    å„æ©Ÿèƒ½ã‚’é©åˆ‡ã«çµ„ã¿åˆã‚ã›ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
    """
    st.title("é¡”ç”»åƒæ“ä½œãƒ—ãƒ­ã‚°ãƒ©ãƒ  (æ”¹å–„ç‰ˆ)")
    st.markdown("**èªçŸ¥å¿ƒç†å­¦å®Ÿé¨“ç”¨ é¡”ç”»åƒæ“ä½œãƒ„ãƒ¼ãƒ«** - é«˜ç²¾åº¦åº§æ¨™å‡¦ç†ãƒ»ä¿¡é ¼åº¦è©•ä¾¡å¯¾å¿œ")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸFaceDetectorã‚’å–å¾—
    detector = get_face_detector()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ¶å¾¡
    parameters = create_parameter_controls()
    
    # å¼·åŒ–ã•ã‚ŒãŸç‰¹å¾´ç‚¹èª¿æ•´ã®åˆ¶å¾¡UI
    enable_landmark_adjustment = create_enhanced_landmark_adjustment_controls()
    
    # ãƒ¡ã‚¤ãƒ³ç”»é¢
    uploaded_file = st.file_uploader(
        "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", 
        type=['jpg', 'jpeg', 'png', 'bmp'],
        help="é¡”ãŒ1ã¤ã ã‘å†™ã£ãŸæ­£é¢å‘ãã®ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚æ¨å¥¨ã‚µã‚¤ã‚º: 500x500pxä»¥ä¸Š"
    )
    
    if uploaded_file is not None:
        # ç”»åƒå¤‰æ›´ã®æ¤œå‡º
        image_bytes = uploaded_file.getvalue()
        detect_image_change(image_bytes)
        
        cv_image, pil_image = load_image_from_uploaded_file(uploaded_file)
        
        if cv_image is not None:
            landmarks, error_message = detector.detect_face_landmarks(cv_image)
            
            if error_message:
                st.error(error_message)
            else:
                # ç”»åƒè¡¨ç¤ºï¼ˆå·¦å³ä¸¦åˆ—ï¼‰
                col1, col2 = st.columns(2)
                
                # å·¦ã‚«ãƒ©ãƒ ï¼šç‰¹å¾´ç‚¹èª¿æ•´ãŒæœ‰åŠ¹ãªå ´åˆã¯ã‚­ãƒ£ãƒ³ãƒã‚¹ã€ç„¡åŠ¹ãªå ´åˆã¯å…ƒç”»åƒ
                with col1:
                    if enable_landmark_adjustment:
                        st.subheader("ğŸ¯ ç‰¹å¾´ç‚¹èª¿æ•´ã‚­ãƒ£ãƒ³ãƒã‚¹")
                        st.caption("è‰²ä»˜ãã®ç‚¹ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã—ã¦ç‰¹å¾´ç‚¹ã‚’èª¿æ•´ã—ã¦ãã ã•ã„")
                        
                        # å¼·åŒ–ã•ã‚ŒãŸã‚­ãƒ£ãƒ³ãƒã‚¹ä½œæˆ
                        landmark_adjustments = create_enhanced_interactive_canvas(
                            landmarks, cv_image.shape, pil_image
                        )
                    else:
                        st.subheader("å…ƒç”»åƒ")
                        st.image(pil_image, caption=f"ã‚µã‚¤ã‚º: {pil_image.size[0]}Ã—{pil_image.size[1]}px")
                        landmark_adjustments = None
                
                # å³ã‚«ãƒ©ãƒ ï¼šæ“ä½œå¾Œç”»åƒ
                with col2:
                    st.subheader("æ“ä½œå¾Œç”»åƒ (ç‰¹å¾´ç‚¹è¡¨ç¤º)")
                    
                    # è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³
                    show_confidence = st.checkbox("ä¿¡é ¼åº¦æƒ…å ±ã‚’è¡¨ç¤º", value=False)
                    show_debug = st.checkbox("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º", value=False)
                    
                    # ç‰¹å¾´ç‚¹ãŒèª¿æ•´ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯èª¿æ•´æ¸ˆã¿landmarkã‚’ä½¿ç”¨
                    display_landmarks = landmarks
                    if landmark_adjustments:
                        display_landmarks = detector.adjust_landmarks(
                            landmarks, landmark_adjustments, cv_image.shape
                        )
                    
                    # ä¿¡é ¼åº¦ä»˜ãã§ç‰¹å¾´ç‚¹ã‚’æç”»
                    annotated_image = detector.draw_landmarks_with_confidence(
                        cv_image, display_landmarks, show_confidence
                    )
                    rgb_annotated = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)
                    st.image(rgb_annotated, caption="å‡¦ç†æ¸ˆã¿ç”»åƒ")
                
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¡¨ç¤º
                display_parameter_metrics(parameters)
                
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤ºï¼ˆæŠ€è¡“çš„ãªè©³ç´°ï¼‰
                if show_debug:
                    st.subheader("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
                    
                    col_debug1, col_debug2 = st.columns(2)
                    
                    with col_debug1:
                        st.write(f"**æ¤œå‡ºã•ã‚ŒãŸç‰¹å¾´ç‚¹æ•°**: {len(landmarks.landmark)}")
                        st.write(f"**ç”»åƒã‚µã‚¤ã‚º**: {cv_image.shape}")
                        st.write(f"**ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚º**: {calculate_canvas_dimensions(cv_image.shape)}")
                        
                        # åº§æ¨™å¤‰æ›ã®æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ
                        test_coords = {'x': 100.0, 'y': 100.0}
                        real_size = (cv_image.shape[1], cv_image.shape[0])
                        canvas_size = calculate_canvas_dimensions(cv_image.shape)
                        is_valid = CoordinateConverter.verify_conversion_integrity(
                            test_coords, real_size, canvas_size
                        )
                        st.write(f"**åº§æ¨™å¤‰æ›æ•´åˆæ€§**: {'âœ… æ­£å¸¸' if is_valid else 'âŒ ç•°å¸¸'}")
                    
                    with col_debug2:
                        # å¼·åŒ–ã•ã‚ŒãŸãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æƒ…å ±
                        enhanced_landmarks = detector.get_enhanced_landmarks(landmarks, cv_image.shape)
                        st.write(f"**å¼·åŒ–ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ•°**: {len(enhanced_landmarks)}")
                        
                        # ä¿¡é ¼åº¦æƒ…å ±
                        if enhanced_landmarks:
                            st.write("**ä¿¡é ¼åº¦è©•ä¾¡**:")
                            for point_name in enhanced_landmarks:
                                confidence_info = LandmarkAnalyzer.assess_landmark_confidence(
                                    landmarks, point_name, cv_image.shape
                                )
                                status_emoji = {'high': 'ğŸŸ¢', 'medium': 'ğŸŸ¡', 'low': 'ğŸ”´'}
                                emoji = status_emoji.get(confidence_info['status'], 'âšª')
                                st.write(f"{emoji} {point_name}: {confidence_info['confidence']:.2f}")
                    
                    # è©³ç´°ãªåº§æ¨™æƒ…å ±
                    with st.expander("ğŸ“Š è©³ç´°åº§æ¨™æƒ…å ±"):
                        if landmark_adjustments:
                            st.write("**èª¿æ•´æ¸ˆã¿åº§æ¨™**:")
                            st.json(landmark_adjustments)
                        
                        if enhanced_landmarks:
                            st.write("**å¼·åŒ–ã•ã‚ŒãŸãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™**:")
                            st.json({k: f"({v['x']:.1f}, {v['y']:.1f})" for k, v in enhanced_landmarks.items()})
                    
                    # é‡è¦ãªç‰¹å¾´ç‚¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±
                    with st.expander("ğŸ“š ç‰¹å¾´ç‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‚ç…§"):
                        st.markdown("""
                        **æ”¹å–„ã•ã‚ŒãŸæ©Ÿèƒ½:**
                        - âœ¨ **è¤‡æ•°ç‚¹å¹³å‡åŒ–**: ã‚ˆã‚Šå®‰å®šã—ãŸç‰¹å¾´ç‚¹æ¤œå‡º
                        - ğŸ¯ **é«˜ç²¾åº¦åº§æ¨™å¤‰æ›**: æµ®å‹•å°æ•°ç‚¹ã«ã‚ˆã‚‹èª¤å·®æœ€å°åŒ–
                        - ğŸ“Š **ä¿¡é ¼åº¦è©•ä¾¡**: æ¤œå‡ºå“è³ªã®å¯è¦–åŒ–
                        - ğŸ”§ **ç²¾å¯†èª¿æ•´**: ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã«ã‚ˆã‚‹ãƒ”ã‚¯ã‚»ãƒ«å˜ä½èª¿æ•´
                        - âš–ï¸ **è§£å‰–å­¦çš„åˆ¶ç´„**: ä¸è‡ªç„¶ãªèª¿æ•´ã®è­¦å‘Š
                        - ğŸ“± **å¿œç­”æ€§UI**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åæ˜ ã¨å±¥æ­´ç®¡ç†
                        
                        **ç‰¹å¾´ç‚¹ã‚°ãƒ«ãƒ¼ãƒ—å®šç¾©:**
                        - å·¦ç›®ä¸­å¿ƒ: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 159, 158, 157, 173 ã®å¹³å‡
                        - å³ç›®ä¸­å¿ƒ: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 386, 385, 384, 398 ã®å¹³å‡
                        - é¼»å…ˆ: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 1, 2 ã®å¹³å‡
                        - é¼»æ¢: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 6, 9 ã®å¹³å‡
                        - å·¦å°é¼»: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 131, 134, 126 ã®å¹³å‡
                        - å³å°é¼»: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 102, 49, 48 ã®å¹³å‡
                        """)
    else:
        st.info("ğŸ–¼ï¸ JPGã€PNGã€BMPå½¢å¼ã®é¡”ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.markdown("""
        ### ğŸ’¡ æ”¹å–„ã•ã‚ŒãŸä½¿ã„æ–¹
        
        **1. ğŸ“· ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**
        - é¡”ãŒ1ã¤ã ã‘å†™ã£ãŸæ­£é¢å‘ãã®ç”»åƒã‚’é¸æŠ
        - æ¨å¥¨ã‚µã‚¤ã‚º: 500Ã—500ãƒ”ã‚¯ã‚»ãƒ«ä»¥ä¸Š
        - ã‚µãƒãƒ¼ãƒˆå½¢å¼: JPG, PNG, BMP
        
        **2. ğŸ›ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´**
        - ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã¾ãŸã¯æ•°å€¤å…¥åŠ›
        - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        - ãƒ—ãƒªã‚»ãƒƒãƒˆæ©Ÿèƒ½ã§ä¸€æ‹¬è¨­å®š
        
        **3. ğŸ¯ é«˜ç²¾åº¦ç‰¹å¾´ç‚¹èª¿æ•´**
        - **ãƒ‰ãƒ©ãƒƒã‚°æ“ä½œ**: ãƒã‚¦ã‚¹ã§ç›´æ„Ÿçš„ã«èª¿æ•´
        - **ç²¾å¯†èª¿æ•´**: ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§ãƒ”ã‚¯ã‚»ãƒ«å˜ä½ã®å¾®èª¿æ•´
        - **ä¿¡é ¼åº¦è¡¨ç¤º**: æ¤œå‡ºå“è³ªã‚’è‰²ã§ç¢ºèª
        - **è¤‡æ•°ç‚¹å¹³å‡åŒ–**: ã‚ˆã‚Šå®‰å®šã—ãŸæ¤œå‡º
        
        **4. ğŸ”„ å“è³ªä¿è¨¼æ©Ÿèƒ½**
        - **åº§æ¨™å¤‰æ›æ•´åˆæ€§**: é«˜ç²¾åº¦æµ®å‹•å°æ•°ç‚¹å‡¦ç†
        - **è§£å‰–å­¦çš„åˆ¶ç´„**: ä¸è‡ªç„¶ãªèª¿æ•´ã®è‡ªå‹•è­¦å‘Š
        - **å±¥æ­´ç®¡ç†**: å…ƒã«æˆ»ã™ãƒ»ã‚„ã‚Šç›´ã—æ©Ÿèƒ½
        - **ãƒ‡ãƒãƒƒã‚°æƒ…å ±**: æŠ€è¡“è€…å‘ã‘è©³ç´°è¡¨ç¤º
        
        **5. ğŸ›¡ï¸ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**
        - è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        - ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒã‚§ãƒƒã‚¯
        - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
        """)

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
ãƒ†ã‚¹ãƒˆç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªé¡”ç‰¹å¾´ç‚¹æ¤œå‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ–ãƒ©ã‚¦ã‚¶ä¸è¦ã§ãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿè¡Œå¯èƒ½
"""

import cv2
import numpy as np
import mediapipe as mp
from PIL import Image
import sys
import os

# MediaPipeè¨­å®š
mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

# ç‰¹å¾´ç‚¹ã‚°ãƒ«ãƒ¼ãƒ—å®šç¾©
LANDMARK_GROUPS = {
    'nose_tip': {'indices': [1, 2], 'label': 'é¼»å…ˆ'},
    'nose_bridge': {'indices': [6, 9], 'label': 'é¼»æ¢'},
    'left_nostril': {'indices': [131, 134, 126], 'label': 'å·¦å°é¼»'},
    'right_nostril': {'indices': [102, 49, 48], 'label': 'å³å°é¼»'},
    'left_eye_center': {'indices': [159, 158, 157, 173], 'label': 'å·¦ç›®'},
    'right_eye_center': {'indices': [386, 385, 384, 398], 'label': 'å³ç›®'}
}

def detect_face_landmarks(image_path):
    """é¡”ç‰¹å¾´ç‚¹ã‚’æ¤œå‡ºã—ã¦ãƒ†ã‚¹ãƒˆ"""
    # ç”»åƒã‚’èª­ã¿è¾¼ã¿
    if not os.path.exists(image_path):
        print(f"âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
        return False
    
    try:
        # OpenCVã§ç”»åƒã‚’èª­ã¿è¾¼ã¿
        image = cv2.imread(image_path)
        if image is None:
            print(f"âŒ ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {image_path}")
            return False
        
        print(f"âœ… ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {image.shape}")
        
        # MediaPipe Face Meshã‚’åˆæœŸåŒ–
        face_mesh = mp_face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5
        )
        
        # BGRã‹ã‚‰RGBã«å¤‰æ›
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = face_mesh.process(rgb_image)
        
        if not results.multi_face_landmarks:
            print("âŒ é¡”ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return False
        
        print("âœ… é¡”ã‚’æ¤œå‡ºã—ã¾ã—ãŸï¼")
        landmarks = results.multi_face_landmarks[0]
        print(f"âœ… ç‰¹å¾´ç‚¹æ•°: {len(landmarks.landmark)}")
        
        # é‡è¦ãªç‰¹å¾´ç‚¹ã®åº§æ¨™ã‚’è¨ˆç®—
        h, w = image.shape[:2]
        print(f"\nğŸ“ ä¸»è¦ç‰¹å¾´ç‚¹ã®åº§æ¨™:")
        
        for name, config in LANDMARK_GROUPS.items():
            # è¤‡æ•°ç‚¹ã®å¹³å‡ã‚’è¨ˆç®—
            points = []
            for idx in config['indices']:
                if idx < len(landmarks.landmark):
                    point = landmarks.landmark[idx]
                    points.append({
                        'x': point.x * w,
                        'y': point.y * h
                    })
            
            if points:
                center_x = sum(p['x'] for p in points) / len(points)
                center_y = sum(p['y'] for p in points) / len(points)
                print(f"  {config['label']}: ({center_x:.1f}, {center_y:.1f})")
        
        # æ³¨é‡ˆä»˜ãç”»åƒã‚’ä½œæˆ
        annotated_image = image.copy()
        
        # é¡”ãƒ¡ãƒƒã‚·ãƒ¥ã‚’æç”»
        mp_drawing.draw_landmarks(
            image=annotated_image,
            landmark_list=landmarks,
            connections=mp_face_mesh.FACEMESH_CONTOURS,
            landmark_drawing_spec=None,
            connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()
        )
        
        # é‡è¦ç‰¹å¾´ç‚¹ã‚’å¼·èª¿
        colors = {
            'nose_tip': (0, 255, 0),      # ç·‘
            'nose_bridge': (0, 170, 0),   # æš—ã„ç·‘
            'left_nostril': (255, 0, 0),  # é’
            'right_nostril': (255, 102, 0), # æ˜ã‚‹ã„é’
            'left_eye_center': (0, 0, 255),  # èµ¤
            'right_eye_center': (0, 102, 255) # ã‚ªãƒ¬ãƒ³ã‚¸
        }
        
        for name, config in LANDMARK_GROUPS.items():
            points = []
            for idx in config['indices']:
                if idx < len(landmarks.landmark):
                    point = landmarks.landmark[idx]
                    points.append({
                        'x': point.x * w,
                        'y': point.y * h
                    })
            
            if points:
                center_x = int(sum(p['x'] for p in points) / len(points))
                center_y = int(sum(p['y'] for p in points) / len(points))
                
                color = colors.get(name, (255, 255, 255))
                cv2.circle(annotated_image, (center_x, center_y), 8, color, -1)
                cv2.circle(annotated_image, (center_x, center_y), 10, (255, 255, 255), 2)
        
        # çµæœç”»åƒã‚’ä¿å­˜
        output_path = image_path.replace('.', '_detected.')
        cv2.imwrite(output_path, annotated_image)
        print(f"\nâœ… çµæœç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ” é¡”ç‰¹å¾´ç‚¹æ¤œå‡ºãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    # å¼•æ•°ã§ç”»åƒãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆ
    if len(sys.argv) > 1:
        image_path = sys.argv[1]
        success = detect_face_landmarks(image_path)
        if success:
            print("\nğŸ‰ ãƒ†ã‚¹ãƒˆå®Œäº†ï¼Streamlitã‚¢ãƒ—ãƒªã‚‚æ­£å¸¸ã«å‹•ä½œã™ã‚‹ã¯ãšã§ã™ã€‚")
        else:
            print("\nâŒ ãƒ†ã‚¹ãƒˆå¤±æ•—ã€‚ç”»åƒã‚„ç’°å¢ƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        print("ä½¿ç”¨æ–¹æ³•: python test_app.py <ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹>")
        print("ä¾‹: python test_app.py sample_face.jpg")
        
        # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®ãƒ‘ã‚¹ã‚’ææ¡ˆ
        possible_paths = [
            "sample.jpg", "test.jpg", "face.jpg", "image.jpg",
            "~/Downloads/sample.jpg", "~/Desktop/sample.jpg"
        ]
        
        print("\nğŸ“ ä»¥ä¸‹ã®ã‚ˆã†ãªç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„ã—ã¦ãã ã•ã„:")
        print("  - é¡”ãŒæ­£é¢ã‚’å‘ã„ãŸç”»åƒ")
        print("  - JPGã€PNGã€BMPå½¢å¼")
        print("  - 500x500ãƒ”ã‚¯ã‚»ãƒ«ä»¥ä¸Šæ¨å¥¨")

if __name__ == "__main__":
    main()